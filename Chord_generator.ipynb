{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc3fef7-a26c-4d98-a762-0c44c780cd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12082c7c-6d2d-448d-95f8-a28b4df485a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "data = pd.read_csv('chords_and_lyrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3d5835-a7e2-4c73-99aa-3eea2aeb0f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a153e38-6d8a-4641-8ef2-aa8fc312c99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out all non-English songs\n",
    "df_filtered = data[data['lang'] == 'en']\n",
    "\n",
    "# Drop unnecessary columns that aren't needed for model training\n",
    "df_filtered = df_filtered.drop(columns=['Unnamed: 0', 'artist_id', 'followers', 'genres', 'popularity', 'name_e_chords', 'tabs'])\n",
    "\n",
    "# Handle missing values (if any)\n",
    "df_filtered = df_filtered.dropna(subset=['chords', 'lyrics'])\n",
    "\n",
    "# Preview the cleaned dataset\n",
    "print(df_filtered.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703af6fb-7ee0-4b92-85e4-9741d188fc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "# Function to parse chord dictionary and get the chord progression\n",
    "def parse_chords(chord_dict):\n",
    "    try:\n",
    "        chord_dict = ast.literal_eval(chord_dict)\n",
    "        # Extract chord progression\n",
    "        chords = ' '.join([chord for chord in chord_dict.values()])\n",
    "        return chords\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "# Function to parse lyrics dictionary and get the lyrics\n",
    "def parse_lyrics(lyric_dict):\n",
    "    try:\n",
    "        lyric_dict = ast.literal_eval(lyric_dict)\n",
    "        # Extract lyrics text\n",
    "        lyrics = ' '.join([lyric for lyric in lyric_dict.values()])\n",
    "        return lyrics\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "# Apply parsing functions\n",
    "df_filtered['chord_progression'] = df_filtered['chords'].apply(parse_chords)\n",
    "df_filtered['lyrics_text'] = df_filtered['lyrics'].apply(parse_lyrics)\n",
    "\n",
    "# Preview the results\n",
    "print(df_filtered[['song_name', 'chord_progression', 'lyrics_text']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab551c6-2148-491f-ab46-db781ada4f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize the TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "\n",
    "# Fit and transform the lyrics\n",
    "X_lyrics = vectorizer.fit_transform(df_filtered['lyrics_text'])\n",
    "\n",
    "# Preview the vectorized lyrics\n",
    "print(X_lyrics.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b6f7dc-d6f4-4a41-b9a9-3aa965778fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding, Dropout\n",
    "\n",
    "# Parameters\n",
    "num_chords = len(set(' '.join(df_filtered['chord_progression']).split()))  # Number of unique chords\n",
    "max_lyrics_length = max(df_filtered['lyrics_text'].apply(lambda x: len(x.split())))  # Max length of lyrics\n",
    "\n",
    "# Build LSTM model\n",
    "model = Sequential()\n",
    "\n",
    "# Embedding layer for lyrics input\n",
    "model.add(Embedding(input_dim=len(vectorizer.get_feature_names_out()), output_dim=100, input_length=max_lyrics_length))\n",
    "\n",
    "# LSTM layers\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Output layer for chord prediction\n",
    "model.add(Dense(num_chords, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae3132b-5120-44e7-9765-3d044fc3caf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Encode chords into integers\n",
    "encoder = LabelEncoder()\n",
    "y_chords = encoder.fit_transform(df_filtered['chord_progression'])\n",
    "\n",
    "# Convert to one-hot encoding\n",
    "y_chords_onehot = to_categorical(y_chords)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_lyrics, y_chords_onehot, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb50d611-1256-4534-b458-cdabfe11ece5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into input (lyrics) and target (chords)\n",
    "lyrics = df_filtered['lyrics'].values\n",
    "chords = df_filtered['chords'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1708921e-ae13-4032-97b2-fe5a6a9a8f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Define tokenization function\n",
    "def tokenize_lyrics(lyrics):\n",
    "    return lyrics.split(\"\\n\")  # Split lyrics by newlines\n",
    "\n",
    "def tokenize_chords(chords):\n",
    "    return chords.split(\"\\n\")  # Split chords by newlines\n",
    "\n",
    "# Tokenize the lyrics and chords\n",
    "tokenized_lyrics = [tokenize_lyrics(lyric) for lyric in df_filtered['lyrics'].tolist()]\n",
    "tokenized_chords = [tokenize_chords(chord) for chord in df_filtered['chords'].tolist()]\n",
    "\n",
    "# Display example of tokenized lyrics and chords\n",
    "print(tokenized_lyrics[0])\n",
    "print(tokenized_chords[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fcc073-47db-42d5-a518-cb8fce0bc9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer for lyrics and chords\n",
    "lyrics_tokenizer = Tokenizer()\n",
    "lyrics_tokenizer.fit_on_texts(tokenized_lyrics)\n",
    "\n",
    "chords_tokenizer = Tokenizer()\n",
    "chords_tokenizer.fit_on_texts(tokenized_chords)\n",
    "\n",
    "# Convert tokenized text into sequences\n",
    "lyrics_sequences = lyrics_tokenizer.texts_to_sequences(tokenized_lyrics)\n",
    "chords_sequences = chords_tokenizer.texts_to_sequences(tokenized_chords)\n",
    "\n",
    "# Pad sequences for consistency\n",
    "max_lyrics_length = max(len(seq) for seq in lyrics_sequences)\n",
    "max_chords_length = max(len(seq) for seq in chords_sequences)\n",
    "\n",
    "lyrics_sequences_padded = pad_sequences(lyrics_sequences, maxlen=max_lyrics_length, padding='post')\n",
    "chords_sequences_padded = pad_sequences(chords_sequences, maxlen=max_chords_length, padding='post')\n",
    "\n",
    "# Display example of padded sequences\n",
    "print(lyrics_sequences_padded[0])\n",
    "print(chords_sequences_padded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf5659a-03d8-45fc-80b4-4001fd63553d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Ensure the model is compiled before fitting\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Embedding, Dense, TimeDistributed\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Define model parameters\n",
    "vocab_size_lyrics = len(lyrics_tokenizer.word_index) + 1  # +1 for padding\n",
    "vocab_size_chords = len(chords_tokenizer.word_index) + 1  # +1 for padding\n",
    "embedding_dim = 100\n",
    "hidden_units = 128\n",
    "\n",
    "# Build the Seq2Seq model\n",
    "model = Sequential()\n",
    "\n",
    "# Encoder: LSTM layer for processing lyrics\n",
    "model.add(Embedding(input_dim=vocab_size_lyrics, output_dim=embedding_dim))\n",
    "model.add(LSTM(hidden_units, return_sequences=True))\n",
    "\n",
    "# Decoder: LSTM layer for generating chords\n",
    "model.add(LSTM(hidden_units, return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(vocab_size_chords, activation='softmax')))\n",
    "\n",
    "# Compile the model (make sure this is done before fitting the model)\n",
    "model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Explicitly build the model by calling model.build() (optional)\n",
    "# This helps avoid issues when the input shape is inferred.\n",
    "model.build(input_shape=(None, max_lyrics_length))  # Input shape: (batch_size, max_lyrics_length)\n",
    "\n",
    "# Now the model is compiled and built, we can train it\n",
    "\n",
    "# Prepare the target data by shifting the chords sequence by one step\n",
    "chords_input = chords_sequences_padded[:, :-1]  # Input for the model (not used directly in training)\n",
    "chords_output = chords_sequences_padded[:, 1:]  # Correct output for the model (shifted by one step)\n",
    "\n",
    "# Make sure chords_output has shape (None, timesteps)\n",
    "# Remove any extra dimensions (e.g., reshape from (None, timesteps, 1) to (None, timesteps))\n",
    "# For sparse categorical crossentropy, the target should be a sequence of integers (shape: (None, timesteps))\n",
    "# So, no need to expand the dimensions anymore.\n",
    "# The output should be a sequence of integers, not one-hot encoded vectors.\n",
    "\n",
    "# Train the model\n",
    "model.fit(lyrics_sequences_padded, chords_output, epochs=10, batch_size=32, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015e6e63-5c63-4891-b37e-db10b1d2bc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Prepare the target data by shifting the chords sequence by one step\n",
    "chords_input = chords_sequences_padded[:, :-1]  # Input for the model (not used directly in training)\n",
    "chords_output = chords_sequences_padded[:, 1:]  # Correct output for the model (shifted by one step)\n",
    "\n",
    "# We need to reshape `chords_output` to have the shape (None, timesteps), where each timestep is a chord index\n",
    "# The target should be an integer array where each element is the index of a chord in the vocabulary\n",
    "chords_output = np.expand_dims(chords_output, -1)  # Add an extra dimension to make it (None, timesteps, 1)\n",
    "\n",
    "# Train the model\n",
    "model.fit(lyrics_sequences_padded, chords_output, epochs=10, batch_size=32, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d87c87d-ad1c-4837-987f-1057efef09a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad sequences to ensure consistent input length\n",
    "max_lyrics_length = max([len(seq) for seq in lyrics_seq])\n",
    "lyrics_seq_padded = pad_sequences(lyrics_seq, maxlen=max_lyrics_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d684e0b-b48e-4add-96d1-961994eeefd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_chords_length = max([len(seq) for seq in chords_seq])\n",
    "chords_seq_padded = pad_sequences(chords_seq, maxlen=max_chords_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39bb1d2-6ce7-4619-a84b-f6c7162addc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the number of unique chords (vocabulary size)\n",
    "vocab_size_chords = len(tokenizer_chords.word_index) + 1  # Including padding\n",
    "\n",
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(tokenizer_lyrics.word_index) + 1, output_dim=128, input_length=max_lyrics_length))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(vocab_size_chords, activation='softmax'))  # Output layer should match vocab_size_chords\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fa647b-0f65-4b96-ba27-dfa525af6f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model (you will need to split your data and adjust batch sizes)\n",
    "model.fit(lyrics_seq_padded, chords_seq_padded, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c7bfc1-d0bf-4062-adf3-f365cc8151d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
